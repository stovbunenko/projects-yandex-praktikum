**Рекомендация тарифов**

Есть данные о поведении клиентов, которые уже перешли на тарифы "Смарт" и "Ультра". 

**Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц.** 

**Известно**:
- сalls — количество звонков,
- minutes — суммарная длительность звонков в минутах,
- messages — количество sms-сообщений,
- mb_used — израсходованный интернет-трафик в Мб,
- is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).

**Цель:**

Построить модель для задачи классификации с максимально большим значением *accuracy*, которая выберет подходящий тариф. Предобработка данных не понадобится. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверить *accuracy* на тестовой выборке.

**Выводы проекта:**

- Из обзора данных можно было увидеть, что среднее целевое отличается от 0.5, т.е присутствует дисбаланс классов. Чтобы при разбиении на выборки сохранять данное соотношение, использовали параметр stratify
- У нас получились данные для обучения, валидационная выборка и тестовая выборка.
- Обучая три разные модели были полученны лучшие метрики качества:
  - Датасет df:
    - **Качество модели "Решающее дерево"** 
      - "accuracy" наилучшей модели на валидационной выборке = 0.7978227060653188
      - Параметры лучшей модели:
        - criterion='entropy'
        - max_depth=10
        - min_samples_leaf=11
        - min_samples_split=2,
        - random_state=5
        - splitter='best'
    - **Качество модели "Случайный лес"**
      - "accuracy" наилучшей модели на валидационной выборке = 0.8133748055987559
      - Параметры лучшей модели:
        - criterion='gini'
        - max_depth=12
        - max_features='log2'
        - min_samples_leaf=1
        - min_samples_split=2,
        - n_estimators=30,
        - random_state=5
    - **Качество модели "Логистическая регрессия"**: 
      - "accuracy" наилучшей модели на валидационной выборке = 0.69 (Самое низкое качество!)
  - Датасет df_new:
    - **Качество модели "Решающее дерево"** 
      - "accuracy" наилучшей модели на валидационной выборке = 0.7962674961119751
      - Параметры лучшей модели:
        - criterion='entropy'
        - max_depth=8
        - min_samples_leaf=1
        - min_samples_split=2,
        - random_state=5
        - splitter='best'
    - **Качество модели "Случайный лес"**
      - "accuracy" наилучшей модели на валидационной выборке = 0.8195956454121306
      - Параметры лучшей модели:
        - criterion='gini'
        - max_depth=12
        - max_features='log2'
        - min_samples_leaf=1
        - min_samples_split=2,
        - n_estimators=80,
        - random_state=5
    - **Качество модели "Логистическая регрессия"**: 
      - "accuracy" наилучшей модели на валидационной выборке = 0.70 (Самое низкое качество!)
- такой точности мы добились меняя гиперпараметры. Например глубину дерева и количество деревьев, минимальное количество выборок, которые должны быть у листа (в случайном лесу).
- самая точная модель на валидационной выборке - "Случайный лес", у нее самая большая точность
- объеденили обучающий и валидационный датасет, для того чтобы у модели было больше данных для обучения и протестировали все наши модели со всеми гиперпараметрами и получили следующие данные:
  - "Решающее дерево" - "accuracy" наилучшей модели на тестовой выборке: 0.77760497667185 и 0.78538102643856(df_new)
  - "Случайный лес" - "accuracy" наилучшей модели на тестовой выборке: 0.813374805598755 и 0.821150855365474 (df_new)
  - "Логическая регрессия" - a"accuracy" наилучшей модели на тестовой выборке - 0.70139968895800 и 0.70139968895800 (df_new)
- самая точная модель на тестовой выборке - Случайный лес, у нее самая большая точность. Но нужно также помнить что модель Случайный лес - самая медленная модель.
- самая быстрая модель - "Логическая регрессия", которая хорошо предсказала признак тариф Смарт, но вот с другим признаком (было меньше данных) справилась очень плохо. В итоге у нее самая маленькая "accuracy".
- для каждой модели построили матрицу ошибок, чтобы понять какие значения метод находит лучше, а какие хуже. В итоге: там где у нас было меньше данных (тариф Ультра), все методы сработали с маленькой точностью.
- проанализировав два датасета df и df_new, можно сделать вывод, что в данном случае удаление столбца 'calls' минимально повлияло на наше исследования и данные получились практически одинаковые. 

**Стек:**

pandas, numpy, math, matplotlib, pyplot, scipy, seaborn, sklearn

**Статус проекта:**

Завершен.
